{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import nn\n",
    "import collections\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('solvent_dataset.csv', sep=\"\\t\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "#for quick prototyping epoch count is set to 20\n",
    "epoch_count = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_s():\n",
    "    zest = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    zesp = 0.2\n",
    "    zel = []\n",
    "    maxpr = 0\n",
    "    best_nr = 0\n",
    "    bad_count = 0\n",
    "    for zzyz in range(0,100):\n",
    "\n",
    "        try:\n",
    "            preds1 = pred_model.predict(X_test2,verbose=0,batch_size=512)\n",
    "            #print(preds1)\n",
    "            #print(y_test2)\n",
    "            preds1[preds1>=zesp] = 1\n",
    "            preds1[preds1<1-zesp] = 0\n",
    "            klkl = accuracy_score(y_test2_2, preds1)\n",
    "\n",
    "            if klkl > maxpr:\n",
    "                maxpr = klkl\n",
    "                best_nr = zesp\n",
    "            #print (klkl)\n",
    "        except:\n",
    "            bad_count +=1\n",
    "        if bad_count >4:\n",
    "            break\n",
    "        zesp+=0.005\n",
    "        zel.append(klkl)\n",
    "    #print(best_nr)\n",
    "    #plt.plot(zel)\n",
    "    print(maxpr)\n",
    "    #print(np.array(zel).max())\n",
    "    #plt.plot(zel)\n",
    "    return best_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate morgan FP, may take a while\n",
    "bins_len= 512\n",
    "smiles_train = data[\"RP\"]\n",
    "def vectorize(smiles):\n",
    "    x_one = np.zeros((len(data), 8, bins_len ),dtype=np.int8)\n",
    "    #x_one = []\n",
    "    for ca,smil in enumerate(smiles):\n",
    "        #x_one_ = []\n",
    "        qq = list(smil.split(\".\"))\n",
    "        for fa in range(0,8):\n",
    "            try:\n",
    "                x_one[ca][fa]=np.fromiter((map(int, AllChem.GetMorganFingerprintAsBitVect(AllChem.MolFromSmiles(qq[fa]),3,nBits=bins_len).ToBitString())),int)\n",
    "            except:\n",
    "                pass\n",
    "            #x_one_.append([0 for x in range(0,bins_len)])\n",
    "            #print(smil)\n",
    "        \n",
    "    return x_one\n",
    "X_train = vectorize(smiles_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a numpy array is recommended, to avoid generating morgan FP every time\n",
    "#np.save('X_train_rat.npy', X_train)\n",
    "# npy file can be loaded with:\n",
    "#X_train = np.load(\"X_train_rat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset_t = collections.Counter((\" \".join(list(data.crude))).split(' '))\n",
    "print(charset_t)\n",
    "charset_t=set(charset_t)\n",
    "char_to_int_t = dict((c,i) for i,c in enumerate(charset_t))\n",
    "int_to_char_t = dict((i,c) for i,c in enumerate(charset_t))\n",
    "print(char_to_int_t)\n",
    "embed_t =  len(charset_t)\n",
    "print(embed_t)\n",
    "one_hot_y = np.zeros((len(data), (len(charset_t)) ),dtype=np.int8)\n",
    "len(one_hot_y[0])\n",
    "for i,nam in enumerate(data['crude']):\n",
    "    list_short = list(nam.split(\" \"))\n",
    "    first = True\n",
    "    for z, name in enumerate(list_short):\n",
    "        if first == True:\n",
    "            one_hot_y[i][char_to_int_t[name]] = 1\n",
    "            #first = False\n",
    "        #elif first !=True:\n",
    "        #    one_hot_y[i][char_to_int_t[name]+11] = 1\n",
    "            \n",
    "Y_train = np.array(one_hot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,X_train_flat, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## LSTM ~~~~~~~~~~~~~~\n",
    "encoding_dim = 512  \n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(8,512,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.LSTM(encoding_dim)(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "\n",
    "decoded = layers.Dense(4096, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "#encoder = keras.Model(input_img, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)\n",
    "encoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=autoencoder.fit(X_train2, y_train2_2,epochs=20,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(8,512,))\n",
    "\n",
    "#input_to_model = encoder\n",
    "#x = layers.Dense(32,activation='relu')(input_to_model)\n",
    "'''\n",
    "enc2 = encoder.layers[-8](input_img)\n",
    "enc2 = encoder.layers[-7](enc2)\n",
    "enc2 = encoder.layers[-6](enc2)\n",
    "enc2 = encoder.layers[-5](enc2)\n",
    "\n",
    "enc2 = encoder.layers[-4](enc2)\n",
    "enc2 = encoder.layers[-3](enc2)\n",
    "\n",
    "\n",
    "enc2 = encoder.layers[-2](enc2)\n",
    "'''\n",
    "enc2 = autoencoder.layers[1](input_img)\n",
    "\n",
    "#ls = layers.Dense(64, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(256, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(128, activation=\"relu\")(ls)\n",
    "p = layers.Dense(10, activation=\"sigmoid\",dtype='float32',name=\"classification\")(ls)\n",
    "\n",
    "\n",
    "pred_model = keras.Model(input_img, p)\n",
    "pred_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='binary_accuracy')\n",
    "pred_model.layers[1].trainable=False\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=pred_model.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=256,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = pred_model.predict(X_test2,verbose=1,batch_size=512)\n",
    "#print(preds1)\n",
    "#print(y_test2)\n",
    "ac_sc = get_best_s()\n",
    "preds1[preds1>=ac_sc] = 1\n",
    "preds1[preds1<1-ac_sc] = 0\n",
    "print (accuracy_score(y_test2_2, preds1))\n",
    "print (classification_report(y_test2_2, preds1,target_names = char_to_int_t.keys(), digits = 3))\n",
    "print (multilabel_confusion_matrix(y_test2_2, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train_flat,X_train_flat, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Dense ~~~~~~~~~~~~~~\n",
    "encoding_dim = 512  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(4096,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim,activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "\n",
    "decoded = layers.Dense(4096, activation='sigmoid')(encoded)\n",
    "#resh = layers.Reshape((8,512))(encoded)\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=autoencoder.fit(X_train2, y_train2_2,epochs=20,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(4096,))\n",
    "\n",
    "\n",
    "enc2 = autoencoder.layers[1](input_img)\n",
    "\n",
    "#ls = layers.Dense(64, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(256, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(128, activation=\"relu\")(ls)\n",
    "p = layers.Dense(10, activation=\"sigmoid\",dtype='float32',name=\"classification\")(ls)\n",
    "\n",
    "\n",
    "pred_model = keras.Model(input_img, p)\n",
    "pred_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='binary_accuracy')\n",
    "pred_model.layers[1].trainable=False\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=pred_model.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=256,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = pred_model.predict(X_test2,verbose=1,batch_size=512)\n",
    "\n",
    "ac_sc = get_best_s()\n",
    "preds1[preds1>=ac_sc] = 1\n",
    "preds1[preds1<1-ac_sc] = 0\n",
    "print (accuracy_score(y_test2_2, preds1))\n",
    "print (classification_report(y_test2_2, preds1))\n",
    "print (multilabel_confusion_matrix(y_test2_2, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,X_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 512  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(8,512,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "a = layers.Permute((2,1))(input_img)\n",
    "x = layers.Conv1D(256,12,activation=\"relu\")(a)\n",
    "x1 = layers.MaxPooling1D(2)(x)\n",
    "x2 = layers.Conv1D(128,10, activation='relu')(x1)\n",
    "x3 = layers.MaxPooling1D(2)(x2)\n",
    "x3 = layers.Conv1D(64,10, activation='relu')(x3)\n",
    "x4 = layers.AveragePooling1D()(x3)\n",
    "flat = layers.Flatten()(x4)\n",
    "encoded = layers.Dense(encoding_dim)(flat)\n",
    "d2 = layers.Reshape((128,4))(encoded)\n",
    "d3 = layers.Conv1D(256,1,strides=1, activation='relu')(d2)\n",
    "d4 = layers.UpSampling1D(2)(d3)\n",
    "d5 = layers.Conv1D(256,1,strides=1, activation='relu')(d4)\n",
    "d6 = layers.UpSampling1D(2)(d5)\n",
    "decoded = layers.Conv1D(8,1,strides=1, activation='sigmoid')(d6)\n",
    "decoded = layers.Permute((2,1))(decoded)\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=autoencoder.fit(X_train2, y_train2_2,epochs=20,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(8,512,))\n",
    "\n",
    "#input_to_model = encoder\n",
    "#x = layers.Dense(32,activation='relu')(input_to_model)\n",
    "\n",
    "enc2 = autoencoder.layers[1](input_img)\n",
    "enc2 = autoencoder.layers[2](enc2)\n",
    "enc2 = autoencoder.layers[3](enc2)\n",
    "enc2 = autoencoder.layers[4](enc2)\n",
    "\n",
    "enc2 = autoencoder.layers[5](enc2)\n",
    "enc2 = autoencoder.layers[6](enc2)\n",
    "\n",
    "\n",
    "enc2 = autoencoder.layers[7](enc2)\n",
    "enc2 = autoencoder.layers[8](enc2)\n",
    "enc2 = autoencoder.layers[9](enc2)\n",
    "#ls = layers.Dense(64, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(128, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(64, activation=\"relu\")(ls)\n",
    "p = layers.Dense(10, activation=\"sigmoid\",dtype='float32',name=\"classification\")(ls)\n",
    "\n",
    "\n",
    "pred_model = keras.Model(input_img, p)\n",
    "pred_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='binary_accuracy')\n",
    "pred_model.layers[1].trainable=False\n",
    "pred_model.layers[2].trainable=False\n",
    "pred_model.layers[3].trainable=False\n",
    "pred_model.layers[4].trainable=False\n",
    "pred_model.layers[5].trainable=False\n",
    "pred_model.layers[6].trainable=False\n",
    "pred_model.layers[7].trainable=False\n",
    "pred_model.layers[8].trainable=False\n",
    "pred_model.layers[9].trainable=False\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=pred_model.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=256,shuffle=True,validation_split=0.1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = pred_model.predict(X_test2,verbose=1,batch_size=512)\n",
    "#print(preds1)\n",
    "#print(y_test2)\n",
    "ac_sc = get_best_s()\n",
    "preds1[preds1>=ac_sc] = 1\n",
    "preds1[preds1<1-ac_sc] = 0\n",
    "print (accuracy_score(y_test2_2, preds1))\n",
    "print (classification_report(y_test2_2, preds1))\n",
    "print (multilabel_confusion_matrix(y_test2_2, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
