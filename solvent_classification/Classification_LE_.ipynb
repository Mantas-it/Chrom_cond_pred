{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import nn\n",
    "import collections\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, multilabel_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('solvent_dataset.csv', sep=\"\\t\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "#for quick prototyping epoch count is set to 20\n",
    "epoch_count = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize input \n",
    "smiles_train = data[\"RP\"]\n",
    "print (smiles_train.shape)\n",
    "charset = set(\"\".join(list(data.RP))+\"!E\")\n",
    "char_to_int = dict((c,i+1) for i,c in enumerate(charset))\n",
    "int_to_char = dict((i+1,c) for i,c in enumerate(charset))\n",
    "embed = max([len(smile) for smile in data .RP])\n",
    "print (str(charset))\n",
    "print(len(charset), embed)\n",
    "\n",
    "def vectorize(smiles):\n",
    "        one_hot =  np.zeros((smiles.shape[0], embed ),dtype=np.int8)\n",
    "        print(one_hot.shape)\n",
    "        for i,smile in enumerate(smiles):\n",
    "            #encode the startchar\n",
    "            #encode the rest of the chars\n",
    "            for j,c in enumerate(smile):\n",
    "                one_hot[i,j] = char_to_int[c]\n",
    "            #Encode endchar\n",
    "            \n",
    "        #Return two, one for input and the other for output\n",
    "        return one_hot#, one_hot[:,0:-1,:]\n",
    "X_train = vectorize(smiles_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_s():\n",
    "    zest = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    zesp = 0.2\n",
    "    zel = []\n",
    "    maxpr = 0\n",
    "    best_nr = 0\n",
    "    bad_count = 0\n",
    "    for zzyz in range(0,100):\n",
    "\n",
    "        try:\n",
    "            preds1 = modelx.predict(X_test2,verbose=0,batch_size=512)\n",
    "            #print(preds1)\n",
    "            #print(y_test2)\n",
    "            preds1[preds1>=zesp] = 1\n",
    "            preds1[preds1<1-zesp] = 0\n",
    "            klkl = accuracy_score(y_test2_2, preds1)\n",
    "\n",
    "            if klkl > maxpr:\n",
    "                maxpr = klkl\n",
    "                best_nr = zesp\n",
    "            #print (klkl)\n",
    "        except:\n",
    "            bad_count +=1\n",
    "        if bad_count >4:\n",
    "            break\n",
    "        zesp+=0.005\n",
    "        zel.append(klkl)\n",
    "    #print(best_nr)\n",
    "    #plt.plot(zel)\n",
    "    print(maxpr)\n",
    "    #print(np.array(zel).max())\n",
    "    #plt.plot(zel)\n",
    "    return best_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize output\n",
    "charset_t = collections.Counter((\" \".join(list(data.crude))).split(' '))\n",
    "#charset_t = collections.Counter(list(data.crude))\n",
    "print(charset_t)\n",
    "charset_t=set(charset_t)\n",
    "char_to_int_t = dict((c,i) for i,c in enumerate(charset_t))\n",
    "int_to_char_t = dict((i,c) for i,c in enumerate(charset_t))\n",
    "print(char_to_int_t)\n",
    "embed_t =  len(charset_t)\n",
    "print(embed_t)\n",
    "one_hot_y = np.zeros((len(data), (len(charset_t)) ),dtype=np.int8)\n",
    "len(one_hot_y[0])\n",
    "for i,nam in enumerate(data['crude']):\n",
    "    list_short = list(nam.split(\" \"))\n",
    "    first = True\n",
    "    for z, name in enumerate(list_short):\n",
    "        if first == True:\n",
    "            one_hot_y[i][char_to_int_t[name]] = 1\n",
    "            #first = False\n",
    "        #elif first !=True:\n",
    "        #    one_hot_y[i][char_to_int_t[name]+11] = 1\n",
    "            \n",
    "Y_train = np.array(one_hot_y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_smiles = len(charset) +1\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = keras.Input(shape=(199,),name='inputx')\n",
    "\n",
    "\n",
    "x = layers.Embedding(embed_smiles,12, input_length=199)(inputA)\n",
    "\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "p = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "p = layers.Dense(10, activation=\"sigmoid\",dtype='float32',name=\"classification\")(p)\n",
    "\n",
    "\n",
    "modelx = keras.Model(inputs=inputA, outputs=p)\n",
    "\n",
    "modelx.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='binary_accuracy')\n",
    "print (modelx.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = modelx.fit(X_train2,y_train2_2, epochs=epoch_count, batch_size=256, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = modelx.predict(X_test2,verbose=1,batch_size=512)\n",
    "#print(preds1)\n",
    "#print(y_test2)\n",
    "ac_sc = get_best_s()\n",
    "preds1[preds1>=ac_sc] = 1\n",
    "preds1[preds1<1-ac_sc] = 0\n",
    "print (accuracy_score(y_test2_2, preds1))\n",
    "print (classification_report(y_test2_2, preds1))\n",
    "print (multilabel_confusion_matrix(y_test2_2, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = keras.Input(shape=(199,),name='inputx')\n",
    "\n",
    "\n",
    "x = layers.Embedding(embed_smiles,12, input_length=199)(inputA)\n",
    "\n",
    "x = layers.Permute((2,1))(x)\n",
    "\n",
    "x = layers.LSTM(128,return_sequences=False)(x)\n",
    "\n",
    "p = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "p = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "p = layers.Dense(10, activation=\"sigmoid\",dtype='float32',name=\"classification\")(p)\n",
    "\n",
    "modelx = keras.Model(inputs=inputA, outputs=p)\n",
    "\n",
    "modelx.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='binary_accuracy')\n",
    "print (modelx.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = modelx.fit(X_train2,y_train2_2, epochs=epoch_count, batch_size=256, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = modelx.predict(X_test2,verbose=1,batch_size=512)\n",
    "#print(preds1)\n",
    "#print(y_test2)\n",
    "ac_sc = get_best_s()\n",
    "preds1[preds1>=ac_sc] = 1\n",
    "preds1[preds1<1-ac_sc] = 0\n",
    "print (accuracy_score(y_test2_2, preds1))\n",
    "print (classification_report(y_test2_2, preds1))\n",
    "print (multilabel_confusion_matrix(y_test2_2, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = keras.Input(shape=(199,),name='inputx')\n",
    "\n",
    "\n",
    "x = layers.Embedding(embed_smiles,12, input_length=199)(inputA)\n",
    "\n",
    "\n",
    "\n",
    "k = layers.Conv1D(64,12,activation='relu')(x)\n",
    "k = layers.AveragePooling1D(3)(k)\n",
    "k = layers.Conv1D(64,12,activation='relu')(k)\n",
    "k = layers.AveragePooling1D(3)(k)\n",
    "k = layers.Conv1D(64,5,activation='relu')(k)\n",
    "k = layers.AveragePooling1D(3)(k)\n",
    "\n",
    "k = layers.Flatten()(k)\n",
    "\n",
    "p = layers.Dense(64, activation='relu')(k)\n",
    "\n",
    "#p = layers.Dense(64, activation='relu')(p)\n",
    "\n",
    "p = layers.Dense(10, activation=\"sigmoid\",dtype='float32',name=\"ratio\")(p)\n",
    "\n",
    "modelx = keras.Model(inputs=inputA, outputs=p)\n",
    "\n",
    "modelx.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics='binary_accuracy')\n",
    "modelx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = modelx.fit(X_train2,y_train2_2, epochs=epoch_count, batch_size=256, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = modelx.predict(X_test2,verbose=1,batch_size=512)\n",
    "#print(preds1)\n",
    "#print(y_test2)\n",
    "ac_sc = get_best_s()\n",
    "preds1[preds1>=ac_sc] = 1\n",
    "preds1[preds1<1-ac_sc] = 0\n",
    "print (accuracy_score(y_test2_2, preds1))\n",
    "print (classification_report(y_test2_2, preds1))\n",
    "print (multilabel_confusion_matrix(y_test2_2, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
