{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import nn\n",
    "import collections\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "#from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "#policy = LossScaleOptimizer('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, multilabel_confusion_matrix, mean_squared_error\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ratio_dataset.csv', sep=\"\\t\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "#for quick prototyping epoch count is set to 20\n",
    "epoch_count = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate morgan FP, may take a while\n",
    "bins_len= 512\n",
    "smiles_train = data[\"RP\"]\n",
    "def vectorize(smiles):\n",
    "    x_one = np.zeros((len(data), 8, bins_len ),dtype=np.int8)\n",
    "    #x_one = []\n",
    "    for ca,smil in enumerate(smiles):\n",
    "        #x_one_ = []\n",
    "        qq = list(smil.split(\".\"))\n",
    "        for fa in range(0,8):\n",
    "            try:\n",
    "                x_one[ca][fa]=np.fromiter((map(int, AllChem.GetMorganFingerprintAsBitVect(AllChem.MolFromSmiles(qq[fa]),3,nBits=bins_len).ToBitString())),int)\n",
    "            except:\n",
    "                pass\n",
    "            #x_one_.append([0 for x in range(0,bins_len)])\n",
    "            #print(smil)\n",
    "        \n",
    "    return x_one\n",
    "X_train = vectorize(smiles_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a numpy array is recommended, to avoid generating morgan FP every time\n",
    "#np.save('X_train_rat.npy', X_train)\n",
    "# npy file can be loaded with:\n",
    "#X_train = np.load(\"X_train_rat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize output\n",
    "one_hot_yz = np.zeros((len(data), 1 ),dtype=np.float16)\n",
    "for i,nam in enumerate(data['rat2'])\n",
    "    one_hot_yz[i] = float(nam)          \n",
    "Y_train = np.array(one_hot_yz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,X_train_flat, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## LSTM ~~~~~~~~~~~~~~\n",
    "encoding_dim = 512  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(8,512,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.LSTM(encoding_dim)(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "\n",
    "decoded = layers.Dense(4096, activation='sigmoid')(encoded)\n",
    "#resh = layers.Reshape((8,512))(decoded)\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "#encoder = keras.Model(input_img, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=autoencoder.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(8,512,))\n",
    "\n",
    "\n",
    "enc2 = autoencoder.layers[1](input_img)\n",
    "\n",
    "#ls = layers.Dense(64, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(256, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(128, activation=\"relu\")(ls)\n",
    "p = layers.Dense(1, activation=\"linear\",dtype='float32',name=\"ratio\")(ls)\n",
    "\n",
    "\n",
    "pred_model = keras.Model(input_img, p)\n",
    "pred_model.compile(loss='mse', optimizer=\"adam\")\n",
    "pred_model.layers[1].trainable=False\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=pred_model.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=256,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=modelx.predict(X_test2,verbose=1)\n",
    "\n",
    "print('MSE: ',mean_squared_error([float(x) for x in y_test2_2], [float(x) for x in y_pred2]))\n",
    "\n",
    "#plt.axis([0, 1.1, 0, 1.1])\n",
    "#plt.scatter((y_pred2),(y_test2_2))\n",
    "print('Correlation cof matrix:')\n",
    "print(np.corrcoef([float(x) for x in y_pred2], [float(x) for x in y_test2_2]))\n",
    "X_addC = sm.add_constant([float(x) for x in y_test2_2])\n",
    "result = sm.OLS([float(x) for x in y_pred2], X_addC).fit()\n",
    "print('R2:',result.rsquared,'R2 adj:', result.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train_flat,X_train_flat, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Dense ~~~~~~~~~~~~~~\n",
    "encoding_dim = 512  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(4096,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim,activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "\n",
    "decoded = layers.Dense(4096, activation='sigmoid')(encoded)\n",
    "#resh = layers.Reshape((8,512))(encoded)\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=autoencoder.fit(X_train2, y_train2_2,epochs=20,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(4096,))\n",
    "\n",
    "#input_to_model = encoder\n",
    "#x = layers.Dense(32,activation='relu')(input_to_model)\n",
    "'''\n",
    "enc2 = encoder.layers[-8](input_img)\n",
    "enc2 = encoder.layers[-7](enc2)\n",
    "enc2 = encoder.layers[-6](enc2)\n",
    "enc2 = encoder.layers[-5](enc2)\n",
    "\n",
    "enc2 = encoder.layers[-4](enc2)\n",
    "enc2 = encoder.layers[-3](enc2)\n",
    "\n",
    "\n",
    "enc2 = encoder.layers[-2](enc2)\n",
    "'''\n",
    "enc2 = autoencoder.layers[1](input_img)\n",
    "\n",
    "#ls = layers.Dense(64, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(256, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(128, activation=\"relu\")(ls)\n",
    "p = layers.Dense(1, activation=\"linear\",dtype='float32',name=\"ratio\")(ls)\n",
    "\n",
    "\n",
    "pred_model = keras.Model(input_img, p)\n",
    "pred_model.compile(loss='mse', optimizer=\"adam\")\n",
    "pred_model.layers[1].trainable=False\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train_flat,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=pred_model.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=256,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=modelx.predict(X_test2,verbose=1)\n",
    "\n",
    "print('MSE: ',mean_squared_error([float(x) for x in y_test2_2], [float(x) for x in y_pred2]))\n",
    "\n",
    "#plt.axis([0, 1.1, 0, 1.1])\n",
    "#plt.scatter((y_pred2),(y_test2_2))\n",
    "print('Correlation cof matrix:')\n",
    "print(np.corrcoef([float(x) for x in y_pred2], [float(x) for x in y_test2_2]))\n",
    "X_addC = sm.add_constant([float(x) for x in y_test2_2])\n",
    "result = sm.OLS([float(x) for x in y_pred2], X_addC).fit()\n",
    "print('R2:',result.rsquared,'R2 adj:', result.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,X_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 512  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(8,512,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "a = layers.Permute((2,1))(input_img)\n",
    "x = layers.Conv1D(256,12,activation=\"relu\")(a)\n",
    "x1 = layers.MaxPooling1D(2)(x)\n",
    "x2 = layers.Conv1D(128,10, activation='relu')(x1)\n",
    "x3 = layers.MaxPooling1D(2)(x2)\n",
    "x3 = layers.Conv1D(64,10, activation='relu')(x3)\n",
    "x4 = layers.AveragePooling1D()(x3)\n",
    "flat = layers.Flatten()(x4)\n",
    "encoded = layers.Dense(encoding_dim)(flat)\n",
    "d1 = layers.Dense(64)(encoded)\n",
    "d2 = layers.Reshape((16,4))(d1)\n",
    "d3 = layers.Conv1D(256,1,strides=1, activation='relu')(d2)\n",
    "d4 = layers.UpSampling1D(2)(d3)\n",
    "d4 = layers.UpSampling1D(2)(d4)\n",
    "d5 = layers.Conv1D(256,1,strides=1, activation='relu')(d4)\n",
    "d6 = layers.UpSampling1D(2)(d5)\n",
    "d6 = layers.UpSampling1D(2)(d6)\n",
    "d6 = layers.Conv1D(256,1,strides=1, activation='relu')(d6)\n",
    "d7 =layers. UpSampling1D(2)(d6)\n",
    "decoded = layers.Conv1D(8,1,strides=1, activation='sigmoid')(d7)\n",
    "decoded = layers.Permute((2,1))(decoded)\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=autoencoder.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(8,512,))\n",
    "\n",
    "#input_to_model = encoder\n",
    "#x = layers.Dense(32,activation='relu')(input_to_model)\n",
    "\n",
    "enc2 = autoencoder.layers[1](input_img)\n",
    "enc2 = autoencoder.layers[2](enc2)\n",
    "enc2 = autoencoder.layers[3](enc2)\n",
    "enc2 = autoencoder.layers[4](enc2)\n",
    "\n",
    "enc2 = autoencoder.layers[5](enc2)\n",
    "enc2 = autoencoder.layers[6](enc2)\n",
    "\n",
    "\n",
    "enc2 = autoencoder.layers[7](enc2)\n",
    "enc2 = autoencoder.layers[8](enc2)\n",
    "enc2 = autoencoder.layers[9](enc2)\n",
    "#ls = layers.Dense(64, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(128, activation=\"relu\")(enc2)\n",
    "ls = layers.Dense(64, activation=\"relu\")(ls)\n",
    "p = layers.Dense(1, activation=\"linear\",dtype='float32',name=\"ratio\")(ls)\n",
    "\n",
    "\n",
    "pred_model = keras.Model(input_img, p)\n",
    "pred_model.compile(loss='mse', optimizer=\"adam\")\n",
    "pred_model.layers[1].trainable=False\n",
    "pred_model.layers[2].trainable=False\n",
    "pred_model.layers[3].trainable=False\n",
    "pred_model.layers[4].trainable=False\n",
    "pred_model.layers[5].trainable=False\n",
    "pred_model.layers[6].trainable=False\n",
    "pred_model.layers[7].trainable=False\n",
    "pred_model.layers[8].trainable=False\n",
    "pred_model.layers[9].trainable=False\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2_2,y_test2_2  = train_test_split(X_train,Y_train, test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=pred_model.fit(X_train2, y_train2_2,epochs=epoch_count,batch_size=256,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=modelx.predict(X_test2,verbose=1)\n",
    "\n",
    "print('MSE: ',mean_squared_error([float(x) for x in y_test2_2], [float(x) for x in y_pred2]))\n",
    "\n",
    "#plt.axis([0, 1.1, 0, 1.1])\n",
    "#plt.scatter((y_pred2),(y_test2_2))\n",
    "print('Correlation cof matrix:')\n",
    "print(np.corrcoef([float(x) for x in y_pred2], [float(x) for x in y_test2_2]))\n",
    "X_addC = sm.add_constant([float(x) for x in y_test2_2])\n",
    "result = sm.OLS([float(x) for x in y_pred2], X_addC).fit()\n",
    "print('R2:',result.rsquared,'R2 adj:', result.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
